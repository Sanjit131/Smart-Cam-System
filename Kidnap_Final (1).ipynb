{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kkb-Ne6l4dXy"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python mediapipe ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y mediapipe\n",
        "!pip install mediapipe==0.10.9 ultralytics opencv-python numpy"
      ],
      "metadata": {
        "id": "by5YA7eAkXEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2L-cHzBo4gKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_model_path = \"/content/drive/MyDrive/yolov8n.pt\"\n",
        "if not os.path.exists(yolo_model_path):\n",
        "    raise FileNotFoundError(f\"YOLO model not found at {yolo_model_path}. Please check the path.\")\n",
        "model = YOLO(yolo_model_path)"
      ],
      "metadata": {
        "id": "tUIu2x955KKi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize MediaPipe models\n",
        "mp_face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5)\n",
        "mp_holistic = mp.solutions.holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "mp_pose = mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "mp_hands = mp.solutions.hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)"
      ],
      "metadata": {
        "id": "K0Vrj_I_5ldr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_kidnapping(frame):\n",
        "    \"\"\"Detects signs of kidnapping using MediaPipe Pose & Hands.\"\"\"\n",
        "\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    pose_results = mp_pose.process(rgb_frame)\n",
        "    hand_results = mp_hands.process(rgb_frame)\n",
        "\n",
        "    risk_score = 0\n",
        "    annotations = []\n",
        "\n",
        "    # 1️⃣ **Detect Aggressive Hand Movements (Struggle)**\n",
        "    if hand_results.multi_hand_landmarks:\n",
        "        annotations.append((\"Hand Detected - Possible Struggle\", (10, 40), (0, 255, 255)))\n",
        "        risk_score += 2  # Increase risk score\n",
        "\n",
        "    # 2️⃣ **Detect Unusual Body Poses**\n",
        "    if pose_results.pose_landmarks:\n",
        "        left_wrist = pose_results.pose_landmarks.landmark[mp.solutions.pose.PoseLandmark.LEFT_WRIST]\n",
        "        right_wrist = pose_results.pose_landmarks.landmark[mp.solutions.pose.PoseLandmark.RIGHT_WRIST]\n",
        "        left_shoulder = pose_results.pose_landmarks.landmark[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER]\n",
        "        right_shoulder = pose_results.pose_landmarks.landmark[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER]\n",
        "\n",
        "        # Check if hands are raised or crossed (defensive posture)\n",
        "        if left_wrist.y < left_shoulder.y or right_wrist.y < right_shoulder.y:\n",
        "            annotations.append((\"Hands Raised - Potential Defense\", (10, 70), (255, 0, 0)))\n",
        "            risk_score += 3  # Higher risk\n",
        "\n",
        "    # Add annotations to frame\n",
        "    for text, pos, color in annotations:\n",
        "        cv2.putText(frame, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "\n",
        "    return frame, risk_score\n"
      ],
      "metadata": {
        "id": "ahMGqMIM5pvb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_kidnapping_in_video(video_path, output_video_path):\n",
        "    \"\"\"Processes video with YOLO + MediaPipe and saves output with risk analysis.\"\"\"\n",
        "\n",
        "    # Open video\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise IOError(f\"Cannot open video file: {video_path}\")\n",
        "\n",
        "    # Get video properties\n",
        "    #fps - frames per second\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Define Video Writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    skip_frames = 3  # Skip every 3 frames to improve efficiency\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Skip frames to speed up processing\n",
        "        if frame_count % skip_frames == 0:\n",
        "            # 1️⃣ Detect objects with YOLO\n",
        "            yolo_results = model(frame)\n",
        "            annotated_frame = yolo_results[0].plot()\n",
        "\n",
        "            # 2️⃣ Detect kidnapping risk with MediaPipe\n",
        "            annotated_frame, risk_score = detect_kidnapping(annotated_frame)\n",
        "\n",
        "            # 3️⃣ Overlay risk level\n",
        "            risk_text = \"High Risk of Kidnapping!\" if risk_score >= 3 else \"Safe\"\n",
        "            color = (0, 0, 255) if risk_score >= 3 else (0, 255, 0)\n",
        "            cv2.putText(annotated_frame, risk_text, (10, height - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "\n",
        "            # Write frame to output video\n",
        "            out.write(annotated_frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    print(f\"Kidnapping detection completed. Output saved to: {output_video_path}\")\n"
      ],
      "metadata": {
        "id": "aqIoSzNE5ske"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change video paths accordingly\n",
        "video_path = \"/content/drive/MyDrive/Source/Kidnap.mp4\"  # Replace with test video path\n",
        "output_video_path = \"/content/drive/MyDrive/kidnapping_output1.mp4\"\n",
        "\n",
        "detect_kidnapping_in_video(video_path, output_video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKVlGEnK56IV",
        "outputId": "495b0b4c-9cab-4f24-8fe6-6e579a0427d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 8 cars, 1 truck, 417.6ms\n",
            "Speed: 33.4ms preprocess, 417.6ms inference, 47.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 truck, 162.1ms\n",
            "Speed: 4.3ms preprocess, 162.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 1 truck, 158.6ms\n",
            "Speed: 5.1ms preprocess, 158.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 1 truck, 163.9ms\n",
            "Speed: 6.1ms preprocess, 163.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 truck, 1 traffic light, 157.7ms\n",
            "Speed: 4.1ms preprocess, 157.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 truck, 1 traffic light, 150.2ms\n",
            "Speed: 4.9ms preprocess, 150.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 truck, 1 traffic light, 178.5ms\n",
            "Speed: 3.1ms preprocess, 178.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 truck, 1 traffic light, 163.6ms\n",
            "Speed: 6.3ms preprocess, 163.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 truck, 1 traffic light, 162.3ms\n",
            "Speed: 4.7ms preprocess, 162.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 truck, 1 traffic light, 185.8ms\n",
            "Speed: 5.6ms preprocess, 185.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 truck, 167.2ms\n",
            "Speed: 5.8ms preprocess, 167.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 truck, 157.6ms\n",
            "Speed: 5.0ms preprocess, 157.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 truck, 195.3ms\n",
            "Speed: 5.0ms preprocess, 195.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 2 trucks, 170.4ms\n",
            "Speed: 5.0ms preprocess, 170.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 trucks, 163.2ms\n",
            "Speed: 6.1ms preprocess, 163.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 trucks, 180.9ms\n",
            "Speed: 4.2ms preprocess, 180.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 truck, 150.6ms\n",
            "Speed: 3.8ms preprocess, 150.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 1 truck, 151.5ms\n",
            "Speed: 3.8ms preprocess, 151.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 cars, 1 truck, 167.4ms\n",
            "Speed: 4.2ms preprocess, 167.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 1 truck, 160.1ms\n",
            "Speed: 5.8ms preprocess, 160.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 1 truck, 162.5ms\n",
            "Speed: 4.7ms preprocess, 162.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 truck, 183.1ms\n",
            "Speed: 4.8ms preprocess, 183.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 1 truck, 255.9ms\n",
            "Speed: 4.5ms preprocess, 255.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 truck, 289.8ms\n",
            "Speed: 11.5ms preprocess, 289.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 1 truck, 235.9ms\n",
            "Speed: 11.1ms preprocess, 235.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 1 truck, 262.6ms\n",
            "Speed: 12.4ms preprocess, 262.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 6 cars, 1 truck, 261.5ms\n",
            "Speed: 4.7ms preprocess, 261.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 1 truck, 253.9ms\n",
            "Speed: 5.2ms preprocess, 253.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 1 truck, 266.1ms\n",
            "Speed: 5.0ms preprocess, 266.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 1 truck, 262.8ms\n",
            "Speed: 11.0ms preprocess, 262.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 cars, 1 truck, 168.1ms\n",
            "Speed: 4.5ms preprocess, 168.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 1 truck, 367.5ms\n",
            "Speed: 4.1ms preprocess, 367.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 1 truck, 147.7ms\n",
            "Speed: 2.9ms preprocess, 147.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 truck, 296.9ms\n",
            "Speed: 5.4ms preprocess, 296.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 truck, 166.7ms\n",
            "Speed: 4.6ms preprocess, 166.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 truck, 157.0ms\n",
            "Speed: 4.6ms preprocess, 157.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 1 truck, 167.9ms\n",
            "Speed: 4.7ms preprocess, 167.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 truck, 165.4ms\n",
            "Speed: 5.1ms preprocess, 165.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 1 truck, 1 traffic light, 173.3ms\n",
            "Speed: 4.8ms preprocess, 173.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 truck, 160.4ms\n",
            "Speed: 9.2ms preprocess, 160.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 1 truck, 164.1ms\n",
            "Speed: 5.0ms preprocess, 164.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 trucks, 159.5ms\n",
            "Speed: 4.0ms preprocess, 159.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 truck, 151.6ms\n",
            "Speed: 4.0ms preprocess, 151.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 truck, 158.7ms\n",
            "Speed: 4.0ms preprocess, 158.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 truck, 159.7ms\n",
            "Speed: 4.3ms preprocess, 159.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 truck, 165.5ms\n",
            "Speed: 9.8ms preprocess, 165.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 cars, 1 truck, 1 traffic light, 172.9ms\n",
            "Speed: 4.9ms preprocess, 172.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 truck, 1 traffic light, 156.7ms\n",
            "Speed: 4.9ms preprocess, 156.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 truck, 1 traffic light, 167.4ms\n",
            "Speed: 5.1ms preprocess, 167.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 truck, 1 traffic light, 162.9ms\n",
            "Speed: 4.3ms preprocess, 162.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 truck, 1 traffic light, 157.9ms\n",
            "Speed: 4.0ms preprocess, 157.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 truck, 1 traffic light, 147.7ms\n",
            "Speed: 4.1ms preprocess, 147.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 truck, 1 traffic light, 151.2ms\n",
            "Speed: 4.4ms preprocess, 151.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 truck, 150.0ms\n",
            "Speed: 4.4ms preprocess, 150.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Kidnapping detection completed. Output saved to: /content/drive/MyDrive/kidnapping_output1.mp4\n"
          ]
        }
      ]
    }
  ]
}